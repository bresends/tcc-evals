# TCC Questions CLI - Guia de Uso

Este documento explica como usar a ferramenta CLI para execu√ß√£o automatizada de experimentos com modelos LLM no sistema TCC Questions.

## √çndice

- [Vis√£o Geral](#vis√£o-geral)
- [Configura√ß√£o Inicial](#configura√ß√£o-inicial)
- [Comandos Dispon√≠veis](#comandos-dispon√≠veis)
- [Configura√ß√µes Experimentais](#configura√ß√µes-experimentais)
- [Exemplos Pr√°ticos](#exemplos-pr√°ticos)
- [Solu√ß√£o de Problemas](#solu√ß√£o-de-problemas)

## Vis√£o Geral

A CLI do TCC Questions permite executar experimentos automatizados com diferentes modelos LLM para avaliar respostas √†s 92 perguntas sobre normas t√©cnicas do CBMGO. O sistema suporta m√∫ltiplas configura√ß√µes experimentais e integra√ß√£o com APIs de LLM.

### Funcionalidades Principais

- ‚úÖ Execu√ß√£o automatizada de experimentos
- ‚úÖ Suporte a m√∫ltiplos modelos LLM
- ‚úÖ Diferentes configura√ß√µes experimentais (no-rag, simple-rag, etc.)
- ‚úÖ Integra√ß√£o com GitHub Models e OpenAI
- ‚úÖ Sistema de logging detalhado
- ‚úÖ Modo dry-run para testes
- ‚úÖ Controle de rate limiting
- ‚úÖ Relat√≥rios de progresso em tempo real

## Configura√ß√£o Inicial

### 1. Vari√°veis de Ambiente

Configure as vari√°veis no arquivo `.env`:

```bash
# Para GitHub Models
LLM_API_KEY=ghp_your_github_token_here
LLM_BASE_URL=https://models.github.ai/inference

# Para OpenAI (alternativo)
OPENAI_API_KEY=sk-your_openai_key_here

# Database (j√° configurado)
DATABASE_URL=postgresql://...
```

### 2. Depend√™ncias

Certifique-se de que todas as depend√™ncias est√£o instaladas:

```bash
uv sync
```

### 3. Verifica√ß√£o da Configura√ß√£o

Teste se a configura√ß√£o est√° correta:

```bash
uv run python -m app.cli.main list-models
```

## Comandos Dispon√≠veis

### `list-models`
Lista todos os modelos LLM dispon√≠veis no sistema.

```bash
uv run python -m app.cli.main list-models
```

**Exemplo de sa√≠da:**
```
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ ID ‚îÉ Nome                     ‚îÉ Descri√ß√£o                                    ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ 1  ‚îÇ gemini-2.5-pro           ‚îÇ Google Gemini 2.5 Pro - Modelo avan√ßado     ‚îÇ
‚îÇ 2  ‚îÇ gemini-2.5-flash         ‚îÇ Google Gemini 2.5 Flash - Vers√£o otimizada  ‚îÇ
‚îÇ 3  ‚îÇ openai/gpt-4.0           ‚îÇ OpenAI GPT-4.0 - Modelo de linguagem        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### `status`
Exibe o status dos experimentos por modelo e configura√ß√£o.

```bash
# Status geral
uv run python -m app.cli.main status

# Status filtrado por modelo
uv run python -m app.cli.main status --model "openai/gpt-4.0"

# Status filtrado por configura√ß√£o
uv run python -m app.cli.main status --config "no-rag"
```

**Exemplo de sa√≠da:**
```
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Modelo         ‚îÉ Configura√ß√£o ‚îÉ Conclu√≠dos ‚îÉ Total ‚îÉ Progresso   ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ openai/gpt-4.0 ‚îÇ no-rag       ‚îÇ 8          ‚îÇ 92    ‚îÇ 8/92 (8.7%) ‚îÇ
‚îÇ openai/gpt-4.0 ‚îÇ simple-rag   ‚îÇ 0          ‚îÇ 92    ‚îÇ 0/92 (0.0%) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### `run-experiments`
Executa experimentos automatizados com modelos LLM.

```bash
uv run python -m app.cli.main run-experiments --model "MODELO" --config "CONFIGURA√á√ÉO" [OP√á√ïES]
```

**Par√¢metros obrigat√≥rios:**
- `--model, -m`: Nome do modelo LLM
- `--config, -c`: Configura√ß√£o experimental

**Par√¢metros opcionais:**
- `--questions, -q`: N√∫mero de perguntas a executar (padr√£o: todas)
- `--start-from, -s`: Pergunta inicial (padr√£o: 1)
- `--delay, -d`: Delay entre chamadas da API em segundos (padr√£o: 1.0)
- `--dry-run`: Simular execu√ß√£o sem fazer chamadas de API
- `--overwrite`: Sobrescrever respostas existentes

## Configura√ß√µes Experimentais

O sistema suporta 5 configura√ß√µes experimentais diferentes:

### 1. `no-rag`
- **Descri√ß√£o**: Utiliza apenas o conhecimento pr√©-treinado do modelo
- **Prompt**: "Voc√™ √© um especialista em normas t√©cnicas do CBMGO. Responda com base apenas no seu conhecimento."
- **Uso**: Linha de base para compara√ß√£o

### 2. `simple-rag`
- **Descri√ß√£o**: Inclui busca b√°sica por informa√ß√µes relevantes
- **Prompt**: "Voc√™ √© um especialista em normas t√©cnicas do CBMGO. Use as informa√ß√µes fornecidas para responder com precis√£o."
- **Uso**: RAG b√°sico com recupera√ß√£o de documentos

### 3. `agentic-rag`
- **Descri√ß√£o**: Emprega agentes inteligentes para an√°lise contextual
- **Prompt**: "Voc√™ √© um agente especializado em normas t√©cnicas do CBMGO. Analise a quest√£o, busque informa√ß√µes relevantes e forne√ßa uma resposta estruturada."
- **Uso**: RAG avan√ßado com racioc√≠nio multi-etapas

### 4. `few-shot`
- **Descri√ß√£o**: Aprende atrav√©s de exemplos fornecidos
- **Prompt**: "Voc√™ √© um especialista em normas t√©cnicas do CBMGO. Aqui est√£o alguns exemplos de como responder perguntas similares:"
- **Uso**: Aprendizado por exemplos

### 5. `chain-of-thought`
- **Descri√ß√£o**: Estrutura o racioc√≠nio passo a passo
- **Prompt**: "Voc√™ √© um especialista em normas t√©cnicas do CBMGO. Pense passo a passo antes de responder."
- **Uso**: Racioc√≠nio expl√≠cito e estruturado

## Exemplos Pr√°ticos

### Exemplo 1: Simula√ß√£o B√°sica
Teste o sistema sem gastar tokens da API:

```bash
uv run python -m app.cli.main run-experiments \
  --model "openai/gpt-4.0" \
  --config "no-rag" \
  --questions 5 \
  --dry-run
```

### Exemplo 2: Experimento Real com 10 Perguntas
Execute um experimento real com delay de 2 segundos:

```bash
uv run python -m app.cli.main run-experiments \
  --model "openai/gpt-4.0" \
  --config "no-rag" \
  --questions 10 \
  --delay 2.0
```

### Exemplo 3: Continuar de onde Parou
Continue um experimento a partir da pergunta 21:

```bash
uv run python -m app.cli.main run-experiments \
  --model "gemini-2.5-pro" \
  --config "simple-rag" \
  --start-from 21 \
  --delay 1.5
```

### Exemplo 4: Sobrescrever Respostas Existentes
Reexecute experimentos sobrescrevendo dados existentes:

```bash
uv run python -m app.cli.main run-experiments \
  --model "openai/gpt-4.0" \
  --config "no-rag" \
  --questions 5 \
  --overwrite
```

### Exemplo 5: Experimento Completo
Execute todas as 92 perguntas para um modelo:

```bash
uv run python -m app.cli.main run-experiments \
  --model "openai/gpt-4.0" \
  --config "chain-of-thought" \
  --delay 1.0
```

## Mapeamento de Modelos

O sistema mapeia automaticamente os nomes dos modelos internos para os nomes da API:

| Modelo Interno | API GitHub Models | API OpenAI |
|----------------|-------------------|------------|
| `openai/gpt-4.0` | `OpenAI/gpt-4o` | `gpt-4o` |
| `openai/gpt-4.1` | `OpenAI/gpt-4o` | `gpt-4o` |
| `openai/o3` | `OpenAI/o1-preview` | `o1-preview` |
| `gemini-2.5-pro` | `OpenAI/gpt-4o` | `gpt-4o` |
| `gemini-2.5-flash` | `OpenAI/gpt-4o-mini` | `gpt-4o-mini` |

## Monitoramento e Logs

### Progress Tracking
O sistema exibe progresso em tempo real:

```
üîÑ Processando perguntas [no-rag] ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 80% 0:02:15
‚úÖ #1 (11.17s)
‚úÖ #2 (19.75s)
‚úÖ #3 (15.32s)
```

### Logs Detalhados
Os logs s√£o salvos automaticamente em `experiment_runs.log`:

```bash
tail -f experiment_runs.log
```

### Resumo Final
Ao final da execu√ß√£o, √© exibido um resumo:

```
==================================================
üìä Resumo da Execu√ß√£o
‚úÖ Sucessos: 8
‚ùå Erros: 0
üìà Total processado: 8/10
‚öôÔ∏è Configura√ß√£o: no-rag
ü§ñ Modelo: openai/gpt-4.0
```

## Solu√ß√£o de Problemas

### Erro: Model not found
**Problema**: `Model not found; expected format: {publisher}/{model_name}`

**Solu√ß√£o**: Verifique se o modelo est√° corretamente cadastrado no banco de dados:
```bash
uv run python -m app.cli.main list-models
```

### Erro: API Key not set
**Problema**: `LLM_API_KEY or OPENAI_API_KEY environment variable not set`

**Solu√ß√£o**: Configure as vari√°veis de ambiente no arquivo `.env`:
```bash
echo "LLM_API_KEY=seu_token_aqui" >> .env
```

### Erro: Rate Limiting
**Problema**: Muitas chamadas para a API muito rapidamente

**Solu√ß√£o**: Aumente o delay entre chamadas:
```bash
--delay 3.0
```

### Erro: Timeout
**Problema**: Comando interrompido por timeout

**Solu√ß√£o**: Execute em lotes menores:
```bash
--questions 20
```

### Respostas Duplicadas
**Problema**: Experimento j√° executado anteriormente

**Solu√ß√£o**: Use `--overwrite` para sobrescrever ou verifique o status:
```bash
uv run python -m app.cli.main status --model "modelo" --config "config"
```

## Workflows Recomendados

### Para Pesquisa Acad√™mica

1. **Teste inicial**: Execute dry-run para validar configura√ß√£o
2. **Piloto**: Execute 10 perguntas para cada configura√ß√£o
3. **Valida√ß√£o**: Analise os resultados no dashboard web
4. **Execu√ß√£o completa**: Execute todas as 92 perguntas
5. **An√°lise**: Use ferramentas de an√°lise estat√≠stica

### Para Desenvolvimento

1. **Debug**: Use dry-run para testar altera√ß√µes
2. **Valida√ß√£o**: Execute subset pequeno com dados reais
3. **Benchmark**: Compare diferentes configura√ß√µes
4. **Otimiza√ß√£o**: Ajuste prompts e par√¢metros

## Considera√ß√µes de Custos

- **GitHub Models**: Gratuito com limita√ß√µes de rate
- **OpenAI**: Custos por token (GPT-4o: ~$0.005/1K tokens)
- **Estimativa**: 92 perguntas ‚âà 5-10 USD por modelo/configura√ß√£o

Use `--dry-run` extensivamente para evitar custos desnecess√°rios durante desenvolvimento.

## Pr√≥ximos Passos

Ap√≥s executar os experimentos:

1. Acesse o dashboard web em `http://localhost:8000/dashboard`
2. Visualize a matriz de experimentos em `/experimentos/matriz`
3. Analise resultados individuais
4. Execute an√°lises estat√≠sticas
5. Exporte dados para ferramentas externas

---

**Desenvolvido para o projeto TCC Questions - Sistema de Avalia√ß√£o de LLMs em Normas T√©cnicas do CBMGO**