"""Main CLI application for TCC Questions"""

import typer
from rich.console import Console
from rich.table import Table
from rich.progress import Progress, SpinnerColumn, TextColumn
import time
from typing import Optional

from .experiment_runner import ExperimentRunner

app = typer.Typer(help="CLI para automa√ß√£o de experimentos TCC Questions")
console = Console()


@app.command("run-experiments")
def run_experiments(
    model: str = typer.Option(..., "--model", "-m", help="Nome do modelo LLM a ser testado"),
    config: str = typer.Option(..., "--config", "-c", help="Configura√ß√£o experimental (no-rag, simple-rag, agentic-rag, etc.)"),
    delay: float = typer.Option(1.0, "--delay", "-d", help="Delay entre chamadas da API (segundos)"),
    questions: Optional[int] = typer.Option(None, "--questions", "-q", help="N√∫mero de perguntas a executar (padr√£o: todas)"),
    start_from: int = typer.Option(1, "--start-from", "-s", help="Pergunta inicial (padr√£o: 1)"),
    dry_run: bool = typer.Option(False, "--dry-run", help="Simular execu√ß√£o sem fazer chamadas de API"),
    overwrite: bool = typer.Option(False, "--overwrite", help="Sobrescrever respostas existentes"),
):
    """
    Executa experimentos automatizados com modelos LLM.
    
    Exemplos:
    
        # Executar todas as perguntas com GPT-4 em configura√ß√£o no-rag
        uv run python -m app.cli.main run-experiments --model "gpt-4" --config "no-rag"
        
        # Executar 10 perguntas com delay de 2 segundos
        uv run python -m app.cli.main run-experiments --model "gpt-3.5-turbo" --config "simple-rag" --questions 10 --delay 2.0
        
        # Simular execu√ß√£o sem fazer chamadas
        uv run python -m app.cli.main run-experiments --model "gpt-4" --config "agentic-rag" --dry-run
    """
    
    console.print(f"[bold blue]üß™ Iniciando experimentos automatizados[/bold blue]")
    console.print(f"[green]Modelo:[/green] {model}")
    console.print(f"[green]Configura√ß√£o:[/green] {config}")
    console.print(f"[green]Delay:[/green] {delay}s")
    console.print(f"[green]Modo:[/green] {'üîç Simula√ß√£o' if dry_run else 'üöÄ Execu√ß√£o real'}")
    
    runner = ExperimentRunner(
        model_name=model,
        config=config,
        delay=delay,
        dry_run=dry_run,
        overwrite=overwrite
    )
    
    try:
        runner.run(
            max_questions=questions,
            start_from=start_from
        )
        console.print("[bold green]‚úÖ Experimentos conclu√≠dos com sucesso![/bold green]")
    except KeyboardInterrupt:
        console.print("[yellow]‚ö†Ô∏è Execu√ß√£o interrompida pelo usu√°rio[/yellow]")
    except Exception as e:
        console.print(f"[red]‚ùå Erro durante execu√ß√£o: {e}[/red]")
        raise typer.Exit(1)


@app.command("list-models")
def list_models():
    """Lista os modelos LLM dispon√≠veis no banco de dados."""
    runner = ExperimentRunner("", "", 0, init_openai=False)  # Dummy values, no OpenAI init
    models = runner.get_available_models()
    
    if not models:
        console.print("[yellow]Nenhum modelo encontrado no banco de dados[/yellow]")
        return
    
    table = Table(title="Modelos LLM Dispon√≠veis")
    table.add_column("ID", style="cyan")
    table.add_column("Nome", style="green")
    table.add_column("Descri√ß√£o", style="blue")
    
    for model in models:
        description = model.descricao or "N/A"
        table.add_row(str(model.id), model.nome, description)
    
    console.print(table)


@app.command("list-configs")
def list_configs():
    """Lista as configura√ß√µes experimentais dispon√≠veis."""
    configs = [
        ("no-rag", "Sem uso de RAG (Retrieval-Augmented Generation)"),
        ("simple-rag", "RAG simples com busca b√°sica"),
        ("agentic-rag", "RAG com agentes inteligentes"),
        ("few-shot", "Aprendizado com poucos exemplos"),
        ("chain-of-thought", "Cadeia de pensamento estruturada"),
        ("default", "Configura√ß√£o padr√£o do modelo"),
    ]
    
    table = Table(title="Configura√ß√µes Experimentais")
    table.add_column("Configura√ß√£o", style="cyan")
    table.add_column("Descri√ß√£o", style="green")
    
    for config, description in configs:
        table.add_row(config, description)
    
    console.print(table)


@app.command("status")
def show_status(
    model: Optional[str] = typer.Option(None, "--model", "-m", help="Filtrar por modelo espec√≠fico"),
    config: Optional[str] = typer.Option(None, "--config", "-c", help="Filtrar por configura√ß√£o espec√≠fica"),
):
    """Mostra o status atual dos experimentos."""
    runner = ExperimentRunner("", "", 0, init_openai=False)  # Dummy values, no OpenAI init
    status = runner.get_experiment_status(model_filter=model, config_filter=config)
    
    table = Table(title="Status dos Experimentos")
    table.add_column("Modelo", style="cyan")
    table.add_column("Configura√ß√£o", style="yellow")
    table.add_column("Conclu√≠dos", style="green")
    table.add_column("Total", style="blue")
    table.add_column("Progresso", style="magenta")
    
    for item in status:
        progress = f"{item['completed']}/{item['total']} ({item['percentage']:.1f}%)"
        table.add_row(
            item['model'],
            item['config'],
            str(item['completed']),
            str(item['total']),
            progress
        )
    
    console.print(table)


if __name__ == "__main__":
    app()